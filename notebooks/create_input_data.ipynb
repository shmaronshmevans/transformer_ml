{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from src.processing import hrrr_data\n",
    "from src.processing import nysm_data\n",
    "from src.processing import get_error\n",
    "from src.processing import normalize\n",
    "from src.processing import get_flag\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nysm_cats_path = \"/home/aevans/nwp_bias/src/landtype/data/nysm.csv\"\n",
    "nysm_cats_df = pd.read_csv(nysm_cats_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Western Plateau', 'Eastern Plateau', 'Great Lakes',\n",
       "       'Hudson Valley', 'Coastal', 'Central Lakes', 'Mohawk Valley',\n",
       "       'Champlain Valley', 'Northern Plateau', 'St. Lawrence Valley'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nysm_cats_df['climate_division_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('/home/aevans/transformer_ml/src/data/temp_df/20240325/Hudson Valley/ml_output.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_transformer_output</th>\n",
       "      <th>0_target</th>\n",
       "      <th>1_transformer_output</th>\n",
       "      <th>1_target</th>\n",
       "      <th>2_transformer_output</th>\n",
       "      <th>2_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7788</th>\n",
       "      <td>0.068059</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.222741</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.051457</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7789</th>\n",
       "      <td>-0.303400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.481618</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.437560</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7790</th>\n",
       "      <td>-0.411390</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.476483</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.263312</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7791</th>\n",
       "      <td>0.223385</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.034735</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.041536</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7792</th>\n",
       "      <td>0.615609</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.113829</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.639374</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7793</th>\n",
       "      <td>-0.215738</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.357341</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.165340</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7794</th>\n",
       "      <td>0.410201</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.039925</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.083371</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7795</th>\n",
       "      <td>-0.480180</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.439321</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.187975</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7796</th>\n",
       "      <td>-0.254938</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.323327</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.142254</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7797</th>\n",
       "      <td>-0.249045</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.414813</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.258309</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7798</th>\n",
       "      <td>0.005986</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.031880</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.384605</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7799</th>\n",
       "      <td>0.175994</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.258880</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.139398</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7800</th>\n",
       "      <td>0.025635</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.265697</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.095014</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7801</th>\n",
       "      <td>-0.213309</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.444962</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.401354</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7802</th>\n",
       "      <td>-0.188003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.219376</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.178368</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7803</th>\n",
       "      <td>-0.432395</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.543827</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.528321</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7804</th>\n",
       "      <td>0.506713</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.080700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.246679</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7805</th>\n",
       "      <td>-0.550384</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.596913</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.514963</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7806</th>\n",
       "      <td>-0.110628</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.277213</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.152783</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7807</th>\n",
       "      <td>-0.526844</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.484022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.570291</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0_transformer_output  0_target  1_transformer_output  1_target  \\\n",
       "7788              0.068059       NaN             -0.222741       NaN   \n",
       "7789             -0.303400       NaN             -0.481618       NaN   \n",
       "7790             -0.411390       NaN             -0.476483       NaN   \n",
       "7791              0.223385       NaN              0.034735       NaN   \n",
       "7792              0.615609       NaN              0.113829       NaN   \n",
       "7793             -0.215738       NaN             -0.357341       NaN   \n",
       "7794              0.410201       NaN              0.039925       NaN   \n",
       "7795             -0.480180       NaN             -0.439321       NaN   \n",
       "7796             -0.254938       NaN             -0.323327       NaN   \n",
       "7797             -0.249045       NaN             -0.414813       NaN   \n",
       "7798              0.005986       NaN              0.031880       NaN   \n",
       "7799              0.175994       NaN             -0.258880       NaN   \n",
       "7800              0.025635       NaN             -0.265697       NaN   \n",
       "7801             -0.213309       NaN             -0.444962       NaN   \n",
       "7802             -0.188003       NaN             -0.219376       NaN   \n",
       "7803             -0.432395       NaN             -0.543827       NaN   \n",
       "7804              0.506713       NaN              0.080700       NaN   \n",
       "7805             -0.550384       NaN             -0.596913       NaN   \n",
       "7806             -0.110628       NaN             -0.277213       NaN   \n",
       "7807             -0.526844       NaN             -0.484022       NaN   \n",
       "\n",
       "      2_transformer_output  2_target  \n",
       "7788              0.051457       NaN  \n",
       "7789             -0.437560       NaN  \n",
       "7790             -0.263312       NaN  \n",
       "7791              0.041536       NaN  \n",
       "7792              0.639374       NaN  \n",
       "7793             -0.165340       NaN  \n",
       "7794              0.083371       NaN  \n",
       "7795             -0.187975       NaN  \n",
       "7796             -0.142254       NaN  \n",
       "7797             -0.258309       NaN  \n",
       "7798              0.384605       NaN  \n",
       "7799             -0.139398       NaN  \n",
       "7800             -0.095014       NaN  \n",
       "7801             -0.401354       NaN  \n",
       "7802             -0.178368       NaN  \n",
       "7803             -0.528321       NaN  \n",
       "7804              0.246679       NaN  \n",
       "7805             -0.514963       NaN  \n",
       "7806             -0.152783       NaN  \n",
       "7807             -0.570291       NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def columns_drop(df):\n",
    "    df = df.drop(\n",
    "        columns=[\n",
    "            \"level_0\",\n",
    "            \"index_x\",\n",
    "            \"index_y\",\n",
    "            \"lead time\",\n",
    "            \"lsm\",\n",
    "            \"station_y\",\n",
    "            'lat',\n",
    "            'lon'\n",
    "        ]\n",
    "    )\n",
    "    df = df.rename(columns={'station_x':'station'})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_for_model():\n",
    "    \"\"\"\n",
    "    This function creates and processes data for a LSTM machine learning model.\n",
    "\n",
    "    Args:\n",
    "        station (str): The station identifier for which data is being processed.\n",
    "\n",
    "    Returns:\n",
    "        new_df (pandas DataFrame): A DataFrame containing processed data.\n",
    "        df_train (pandas DataFrame): A DataFrame for training the machine learning model.\n",
    "        df_test (pandas DataFrame): A DataFrame for testing the machine learning model.\n",
    "        features (list): A list of feature names.\n",
    "        forecast_lead (int): The lead time for the target variable.\n",
    "    \"\"\"\n",
    "    # load nysm data\n",
    "    nysm_df = nysm_data.load_nysm_data()\n",
    "    nysm_df.reset_index(inplace=True)\n",
    "    nysm_df = nysm_df.rename(columns={\"time_1H\": \"valid_time\"})\n",
    "\n",
    "    # load hrrr data\n",
    "    hrrr_df = hrrr_data.read_hrrr_data()\n",
    "\n",
    "    # Filter NYSM data to match valid times from HRRR data and save it to a CSV file.\n",
    "    mytimes = hrrr_df[\"valid_time\"].tolist()\n",
    "    nysm_df = nysm_df[nysm_df[\"valid_time\"].isin(mytimes)]\n",
    "\n",
    "    # Filter data by NY climate division \n",
    "    nysm_cats_path = \"/home/aevans/nwp_bias/src/landtype/data/nysm.csv\"\n",
    "    nysm_cats_df = pd.read_csv(nysm_cats_path)\n",
    "    nysm_cats_df = nysm_cats_df[nysm_cats_df['climate_division_name']=='Western Plateau']\n",
    "    stations = nysm_cats_df[\"stid\"].tolist()\n",
    "    nysm_df = nysm_df[nysm_df['station'].isin(stations)]\n",
    "    hrrr_df = hrrr_df[hrrr_df['station'].isin(stations)]\n",
    "\n",
    "    # merge dataframes so that each row is hrrr + nysm data for the same time step\n",
    "    # do this for each station individually \n",
    "    for station in stations:\n",
    "        nysm_df1 = nysm_df[nysm_df['station']==station]\n",
    "        hrrr_df1 = hrrr_df[hrrr_df['station']==station]\n",
    "\n",
    "        master_df = hrrr_df1.merge(nysm_df1, on=\"valid_time\")\n",
    "        master_df = master_df.drop_duplicates(\n",
    "            subset=[\"valid_time\", \"t2m\"], keep=\"first\"\n",
    "        )\n",
    "        master_df = columns_drop(master_df)\n",
    "\n",
    "        # Calculate the error using NWP data.\n",
    "        master_df = get_error.nwp_error(\"t2m\", master_df)\n",
    "        # encode for day_of_year\n",
    "        master_df = normalize.encode(master_df, 'day_of_year', 366)\n",
    "        # get flag for non-consecutive time steps\n",
    "        master_df = get_flag.get_flag(master_df)\n",
    "\n",
    "        cols_to_carry = ['valid_time', 'station', 'latitude', 'longitude', 'flag']\n",
    "\n",
    "        new_df = master_df.drop(columns=cols_to_carry)\n",
    "\n",
    "        new_df, features = normalize.normalize_df(new_df)\n",
    "\n",
    "        # Split the data into training and testing sets.\n",
    "        length = len(new_df)\n",
    "        test_len = int(length * 0.8)\n",
    "        df_train = new_df.iloc[:test_len].copy()\n",
    "        df_test = new_df.iloc[test_len:].copy()\n",
    "        print(\"Test Set Fraction\", len(df_test) / len(new_df))\n",
    "\n",
    "        # Reintegrate the specified columns back into the training and testing DataFrames.\n",
    "        for c in cols_to_carry:\n",
    "            df_train[c] = master_df[c]\n",
    "            df_test[c] = master_df[c]\n",
    "\n",
    "    return df_train, df_test, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train, df_test, features = create_data_for_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nysm_df = nysm_data.load_nysm_data()\n",
    "nysm_df.reset_index(inplace=True)\n",
    "nysm_df = nysm_df.rename(columns={\"time_1H\": \"valid_time\"})\n",
    "nysm_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hrrr_df = hrrr_data.read_hrrr_data()\n",
    "hrrr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path for tabular data.\n",
    "nysm_cats_path = \"/home/aevans/nwp_bias/src/landtype/data/nysm.csv\"\n",
    "nysm_cats_df = pd.read_csv(nysm_cats_path)\n",
    "nysm_cats_df = nysm_cats_df[nysm_cats_df['climate_division_name']=='Western Plateau']\n",
    "nysm_cats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = nysm_cats_df[\"stid\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nysm_df = nysm_df[nysm_df['station'].isin(stations)]\n",
    "hrrr_df = hrrr_df[hrrr_df['station'].isin(stations)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nysm_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hrrr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to create a master list for valid_times so that all the dataframes are the same shape\n",
    "master_time = hrrr_df['valid_time'].tolist()\n",
    "for station in stations:\n",
    "    hrrr_dft = hrrr_df[hrrr_df[\"station\"] == station]\n",
    "    nysm_dft = nysm_df[nysm_df[\"station\"] == station]\n",
    "    times = hrrr_dft['valid_time'].tolist()\n",
    "    times2 = nysm_dft['valid_time'].tolist()\n",
    "    result = list(set(times) & set(master_time) & set(times2))\n",
    "    master_time = result\n",
    "\n",
    "master_time_final = master_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_me1 = (sorted(master_time_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_me1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(master_time_final))\n",
    "sorted(master_time_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(master_time))\n",
    "sorted(master_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for station in stations:\n",
    "    nysm_df1 = nysm_df[nysm_df['station']==station]\n",
    "    hrrr_df1 = hrrr_df[hrrr_df['station']==station]\n",
    "\n",
    "    master_df = hrrr_df1.merge(nysm_df1, on=\"valid_time\")\n",
    "    master_df = master_df.drop_duplicates(\n",
    "        subset=[\"valid_time\", \"t2m\"], keep=\"first\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = columns_drop(master_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the error using NWP data.\n",
    "master_df = get_error.nwp_error(\"t2m\", master_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = normalize.encode(master_df, 'day_of_year', 366)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = get_flag.get_flag(master_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_carry = ['valid_time', 'station', 'latitude', 'longitude', 'flag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = master_df.drop(columns=cols_to_carry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df, features = normalize.normalize_df(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets.\n",
    "length = len(new_df)\n",
    "test_len = int(length * 0.8)\n",
    "df_train = new_df.iloc[:test_len].copy()\n",
    "df_test = new_df.iloc[test_len:].copy()\n",
    "print(\"Test Set Fraction\", len(df_test) / len(new_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reintegrate the specified columns back into the training and testing DataFrames.\n",
    "for c in cols_to_carry:\n",
    "    df_train[c] = master_df[c]\n",
    "    df_test[c] = master_df[c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "44818f36aeaf89db1a1d21a2bee6031a28b4e41595a65903b38b9b0c4417365f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
