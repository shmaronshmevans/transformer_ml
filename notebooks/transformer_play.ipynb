{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torchvision.ops.misc import MLP, Conv2dNormActivation\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "from collections import OrderedDict\n",
    "import math\n",
    "from functools import partial\n",
    "from typing import Any, Callable, Dict, List, NamedTuple, Optional\n",
    "\n",
    "from src.processing import create_data_for_vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Data for Vision Transformer\n",
    "### We will target Western Plateau for consistency "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling Data for ADDI\n",
      "Test Set Fraction 0.2000117792567289\n",
      "train_shape (27166, 34)\n",
      "test_shape (6792, 34)\n",
      "Compiling Data for BELM\n",
      "Test Set Fraction 0.2000117792567289\n",
      "train_shape (27166, 34)\n",
      "test_shape (6792, 34)\n",
      "Compiling Data for COHO\n",
      "Test Set Fraction 0.2000117792567289\n",
      "train_shape (27166, 34)\n",
      "test_shape (6792, 34)\n",
      "Compiling Data for DELE\n",
      "Test Set Fraction 0.2000117792567289\n",
      "train_shape (27166, 34)\n",
      "test_shape (6792, 34)\n",
      "Compiling Data for ELMI\n",
      "Test Set Fraction 0.2000117792567289\n",
      "train_shape (27166, 34)\n",
      "test_shape (6792, 34)\n",
      "Compiling Data for GROV\n",
      "Test Set Fraction 0.2000117792567289\n",
      "train_shape (27166, 34)\n",
      "test_shape (6792, 34)\n",
      "Compiling Data for HART\n",
      "Test Set Fraction 0.2000117792567289\n",
      "train_shape (27166, 34)\n",
      "test_shape (6792, 34)\n",
      "Compiling Data for OLEA\n",
      "Test Set Fraction 0.2000117792567289\n",
      "train_shape (27166, 34)\n",
      "test_shape (6792, 34)\n",
      "Compiling Data for RAND\n",
      "Test Set Fraction 0.2000117792567289\n",
      "train_shape (27166, 34)\n",
      "test_shape (6792, 34)\n"
     ]
    }
   ],
   "source": [
    "df_train_ls, df_test_ls, features = create_data_for_vision.create_data_for_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['t2m', 'sh2', 'd2m', 'r2', 'u10', 'v10', 'tp', 'mslma', 'orog', 'tcc',\n",
       "       'asnow', 'cape', 'dswrf', 'dlwrf', 'gh', 'u_total', 'u_dir', 'new_tp',\n",
       "       'day_of_year_cos', 'day_of_year_sin', 'target_error', 'elev', 'tair',\n",
       "       'ta9m', 'td', 'relh', 'srad', 'pres', 'mslp', 'wspd_sonic',\n",
       "       'wmax_sonic', 'wdir_sonic', 'precip_total', 'snow_depth'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_ls[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiStationDataset(Dataset):\n",
    "    def __init__(self, dataframes, target, features, past_steps, future_steps, nysm_vars=12):\n",
    "        \"\"\"\n",
    "        dataframes: list of station dataframes like in the SequenceDataset\n",
    "        target: target error\n",
    "        features: list of features for model\n",
    "        sequence_length: int\n",
    "        \"\"\"\n",
    "        self.dataframes = dataframes\n",
    "        self.features = features\n",
    "        self.target = target\n",
    "        self.past_steps = past_steps\n",
    "        self.future_steps = future_steps\n",
    "        self.nysm_vars = nysm_vars\n",
    "\n",
    "    def __len__(self):\n",
    "        shaper = min([self.dataframes[i].values.shape[0] - (self.past_steps + self.future_steps) for i in range(len(self.dataframes))])\n",
    "        return shaper\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        # this is the preceeding sequence_length timesteps\n",
    "        x = torch.stack([torch.tensor(dataframe[self.features].values[i : (i + self.past_steps + self.future_steps)]) for dataframe in self.dataframes])\n",
    "        # stacking the sequences from each dataframe along a new axis, so the output is of shape (batch, stations (len(self.dataframes)), past_steps, features)\n",
    "        y = torch.stack([torch.tensor(dataframe[self.target].values[i + self.past_steps : i + self.past_steps + self.future_steps]) for dataframe in self.dataframes])\n",
    "        # this is (batch, stations, future_steps)\n",
    "        x[-self.future_steps:, :self.nysm_vars] = -999.0 # check that this is setting the right positions to this value\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MultiStationDataset(df_train_ls, 'target_error', features, 8, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.MultiStationDataset at 0x7f166411eeb0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = MultiStationDataset(df_test_ls, 'target_error', features, 8, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.ops.misc import MLP, Conv2dNormActivation\n",
    "from collections import OrderedDict\n",
    "import math\n",
    "from functools import partial\n",
    "from typing import Any, Callable, Dict, List, NamedTuple, Optional\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class MLPBlock(MLP):\n",
    "    \"\"\"Transformer MLP block.\"\"\"\n",
    "    _version = 2\n",
    "\n",
    "    def __init__(self, in_dim: int, mlp_dim: int, dropout: float):\n",
    "        super().__init__(in_dim, [mlp_dim, in_dim], activation_layer=nn.GELU, inplace=None, dropout=dropout)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.normal_(m.bias, std=1e-6)\n",
    "\n",
    "    def _load_from_state_dict(\n",
    "        self,\n",
    "        state_dict,\n",
    "        prefix,\n",
    "        local_metadata,\n",
    "        strict,\n",
    "        missing_keys,\n",
    "        unexpected_keys,\n",
    "        error_msgs,\n",
    "    ):\n",
    "        version = local_metadata.get(\"version\", None)\n",
    "\n",
    "        if version is None or version < 2:\n",
    "            # Replacing legacy MLPBlock with MLP. See https://github.com/pytorch/vision/pull/6053\n",
    "            for i in range(2):\n",
    "                for type in [\"weight\", \"bias\"]:\n",
    "                    old_key = f\"{prefix}linear_{i+1}.{type}\"\n",
    "                    new_key = f\"{prefix}{3*i}.{type}\"\n",
    "                    if old_key in state_dict:\n",
    "                        state_dict[new_key] = state_dict.pop(old_key)\n",
    "\n",
    "        super()._load_from_state_dict(\n",
    "            state_dict,\n",
    "            prefix,\n",
    "            local_metadata,\n",
    "            strict,\n",
    "            missing_keys,\n",
    "            unexpected_keys,\n",
    "            error_msgs,\n",
    "        )\n",
    "\n",
    "\n",
    "class EncoderBlock(nn.Module):\n",
    "    \"\"\"Transformer encoder block.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_heads: int,\n",
    "        hidden_dim: int,\n",
    "        mlp_dim: int,\n",
    "        dropout: float,\n",
    "        attention_dropout: float,\n",
    "        norm_layer: Callable[..., torch.nn.Module] = partial(nn.LayerNorm, eps=1e-6),\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        # Attention block\n",
    "        self.ln_1 = norm_layer(hidden_dim)\n",
    "        self.self_attention = nn.MultiheadAttention(hidden_dim, num_heads, dropout=attention_dropout, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # MLP block\n",
    "        self.ln_2 = norm_layer(hidden_dim)\n",
    "        self.mlp = MLPBlock(hidden_dim, mlp_dim, dropout)\n",
    "\n",
    "    def forward(self, input: torch.Tensor):\n",
    "        torch._assert(input.dim() == 3, f\"Expected (batch_size, seq_length, hidden_dim) got {input.shape}\")\n",
    "        x = self.ln_1(input)\n",
    "        x, _ = self.self_attention(x, x, x, need_weights=False)\n",
    "        x = self.dropout(x)\n",
    "        x = x + input\n",
    "\n",
    "        y = self.ln_2(x)\n",
    "        y = self.mlp(y)\n",
    "        return x + y\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"Transformer Model Encoder for sequence to sequence translation.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        seq_length: int,\n",
    "        num_layers: int,\n",
    "        num_heads: int,\n",
    "        hidden_dim: int,\n",
    "        mlp_dim: int,\n",
    "        dropout: float,\n",
    "        attention_dropout: float,\n",
    "        norm_layer: Callable[..., torch.nn.Module] = partial(nn.LayerNorm, eps=1e-6),\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # Note that batch_size is on the first dim because\n",
    "        # we have batch_first=True in nn.MultiAttention() by default\n",
    "        # self.pos_embedding = nn.Parameter(torch.empty(1, seq_length, hidden_dim).normal_(std=0.02))  # from BERT\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        layers: OrderedDict[str, nn.Module] = OrderedDict()\n",
    "        for i in range(num_layers):\n",
    "            layers[f\"encoder_layer_{i}\"] = EncoderBlock(\n",
    "                num_heads,\n",
    "                hidden_dim,\n",
    "                mlp_dim,\n",
    "                dropout,\n",
    "                attention_dropout,\n",
    "                norm_layer,\n",
    "            )\n",
    "        self.layers = nn.Sequential(layers)\n",
    "        self.ln = norm_layer(hidden_dim)\n",
    "\n",
    "    def forward(self, input: torch.Tensor):\n",
    "        torch._assert(input.dim() == 3, f\"Expected (batch_size, seq_length, hidden_dim) got {input.shape}\")\n",
    "        # input = input + self.pos_embedding\n",
    "        return self.ln(self.layers(self.dropout(input)))\n",
    "\n",
    "\n",
    "class VisionTransformer(nn.Module):\n",
    "    \"\"\"Vision Transformer as per https://arxiv.org/abs/2010.11929.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        stations: int,\n",
    "        past_timesteps: int,\n",
    "        future_timesteps: int,\n",
    "        num_vars: int,\n",
    "        num_layers: int = 6,\n",
    "        num_heads: int = 8,\n",
    "        hidden_dim: int = 128,\n",
    "        mlp_dim: int = 768,\n",
    "        dropout: float = 0.0,\n",
    "        attention_dropout: float = 0.0,\n",
    "        num_classes: int = 1,\n",
    "        representation_size: Optional[int] = None,\n",
    "        norm_layer: Callable[..., torch.nn.Module] = partial(nn.LayerNorm, eps=1e-6),\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.future_timesteps = future_timesteps\n",
    "        self.past_timesteps = past_timesteps\n",
    "        self.stations = stations\n",
    "        self.timesteps = future_timesteps + past_timesteps\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.mlp_dim = mlp_dim\n",
    "        self.attention_dropout = attention_dropout\n",
    "        self.dropout = dropout\n",
    "        self.num_classes = num_classes\n",
    "        self.representation_size = representation_size\n",
    "        self.norm_layer = norm_layer\n",
    "        self.num_vars = num_vars\n",
    "\n",
    "        self.mlp = torchvision.ops.MLP(num_vars, [hidden_dim], None, torch.nn.GELU, dropout=dropout)\n",
    "\n",
    "        seq_length = stations * (future_timesteps + past_timesteps)\n",
    "\n",
    "        # Add a class token\n",
    "        self.class_token = nn.Parameter(torch.zeros(1, 1, hidden_dim))\n",
    "        seq_length += 1\n",
    "\n",
    "        self.encoder = Encoder(\n",
    "            seq_length,\n",
    "            num_layers,\n",
    "            num_heads,\n",
    "            hidden_dim,\n",
    "            mlp_dim,\n",
    "            dropout,\n",
    "            attention_dropout,\n",
    "            norm_layer,\n",
    "        )\n",
    "        self.seq_length = seq_length\n",
    "\n",
    "        heads_layers: OrderedDict[str, nn.Module] = OrderedDict()\n",
    "        if representation_size is None:\n",
    "            heads_layers[\"head\"] = nn.Linear(hidden_dim, num_classes)\n",
    "        else:\n",
    "            heads_layers[\"pre_logits\"] = nn.Linear(hidden_dim, representation_size)\n",
    "            heads_layers[\"act\"] = nn.Tanh()\n",
    "            heads_layers[\"head\"] = nn.Linear(representation_size, num_classes)\n",
    "\n",
    "        self.heads = nn.Sequential(heads_layers)\n",
    "\n",
    "        if hasattr(self.heads, \"pre_logits\") and isinstance(self.heads.pre_logits, nn.Linear):\n",
    "            fan_in = self.heads.pre_logits.in_features\n",
    "            nn.init.trunc_normal_(self.heads.pre_logits.weight, std=math.sqrt(1 / fan_in))\n",
    "            nn.init.zeros_(self.heads.pre_logits.bias)\n",
    "\n",
    "        if isinstance(self.heads.head, nn.Linear):\n",
    "            nn.init.zeros_(self.heads.head.weight)\n",
    "            nn.init.zeros_(self.heads.head.bias)\n",
    "\n",
    "    def _process_input(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # n = batch size\n",
    "        # h = number of stations\n",
    "        # w = number of time steps\n",
    "        # c = number of features\n",
    "        n, h, w, c = x.shape\n",
    "        torch._assert(h == self.stations, f\"Wrong image height! Expected {self.stations} but got {h}!\")\n",
    "        torch._assert(w == self.timesteps, f\"Wrong image width! Expected {self.timesteps} but got {w}!\")\n",
    "\n",
    "        print(\"my shape\", x.shape)\n",
    "\n",
    "        # (n, hidden_dim, n_h, n_w) -> (n, hidden_dim, (n_h * n_w))\n",
    "        print(\"# of vars\", self.num_vars)\n",
    "\n",
    "        x = x.reshape(n, h * w, self.num_vars)\n",
    "        x = self.mlp(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        # Reshape and permute the input tensor\n",
    "        x = self._process_input(x)\n",
    "        n = x.shape[0]\n",
    "\n",
    "        # Expand the class token to the full batch\n",
    "        batch_class_token = self.class_token.expand(n, -1, -1)\n",
    "        x = torch.cat([batch_class_token, x], dim=1)\n",
    "\n",
    "        x = self.encoder(x)\n",
    "\n",
    "        # Classifier \"token\" is the future prediction - we will probably just want to select just some of these variables.\n",
    "        # x \\in (batch, stations * timesteps + 1, num_classes = 1)\n",
    "        x = x[:, -(self.stations * self.future_timesteps):, :] # this shape is (batch, stations, num_classes = 1)\n",
    "\n",
    "        x = self.heads(x) # is a linear transformation from hidden_dim to 1\n",
    "        \n",
    "        return x # logically we are saying return one value for the each future timestep for each station (interpreted as error)\n",
    "\n",
    "\n",
    "class AaronFormer(nn.Module):\n",
    "    def __init__(self, \n",
    "                output_dim, \n",
    "                stations,\n",
    "                past_timesteps,\n",
    "                future_timesteps,  \n",
    "                variables,            \n",
    "                num_layers,\n",
    "                num_heads,\n",
    "                hidden_dim,\n",
    "                mlp_dim,\n",
    "                dropout, \n",
    "                attention_dropout,\n",
    "                ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = VisionTransformer(\n",
    "                stations=stations,\n",
    "                past_timesteps=past_timesteps,\n",
    "                future_timesteps=future_timesteps,\n",
    "                num_vars=variables,\n",
    "                num_layers=num_layers,\n",
    "                num_heads=num_heads,\n",
    "                hidden_dim=hidden_dim,\n",
    "                mlp_dim=mlp_dim,\n",
    "                num_classes=output_dim,\n",
    "                dropout=dropout,\n",
    "                attention_dropout=attention_dropout\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AaronFormer(output_dim=8, \n",
    "stations = len(df_train_ls), \n",
    "past_timesteps=8,\n",
    "future_timesteps=8,\n",
    "variables=(len(df_train_ls[0].keys())-1),            \n",
    "num_layers=12,\n",
    "num_heads=12,\n",
    "hidden_dim=768,\n",
    "mlp_dim=3072,\n",
    "dropout=0.0, \n",
    "attention_dropout=0.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 3\n",
    "BATCH_SIZE = 10\n",
    "LEARNING_RATE = 2e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adam Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "# MSE Loss\n",
    "loss_func = nn.MSELoss()\n",
    "# Use GPU if available  \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
    "if torch.cuda.is_available():\n",
    "    model.cuda() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,  num_workers=4)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(data_loader, model, loss_function, optimizer, device, epoch):\n",
    "    num_batches = len(data_loader)\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "    ddp_loss = torch.zeros(2).to(device)\n",
    "\n",
    "    for batch_idx, (X, y) in enumerate(data_loader):\n",
    "        print(\"X shape\", X.shape)\n",
    "        print(\"y shape\", y.shape)\n",
    "        X = X.to(torch.float32)\n",
    "        y = y.to(torch.float32)\n",
    "        # Move data and labels to the appropriate device (GPU/CPU).\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Forward pass and loss computation.\n",
    "        output = model(X)\n",
    "        loss = loss_function(output, y)\n",
    "\n",
    "        # Zero the gradients, backward pass, and optimization step.\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Track the total loss and the number of processed samples.\n",
    "        total_loss += loss.item()\n",
    "        ddp_loss[0] += loss.item()\n",
    "        ddp_loss[1] += len(X)\n",
    "\n",
    "    # Synchronize and aggregate losses in distributed training.\n",
    "    dist.all_reduce(ddp_loss, op=dist.ReduceOp.SUM)\n",
    "\n",
    "    # Compute the average loss for the current epoch.\n",
    "    avg_loss = total_loss / num_batches\n",
    "\n",
    "    # Print the average loss on the master process (rank 0).\n",
    "    if rank == 0:\n",
    "        print(\"Train Epoch: {} \\tLoss: {:.6f}\".format(epoch, ddp_loss[0] / ddp_loss[1]))\n",
    "\n",
    "    return avg_loss\n",
    "\n",
    "\n",
    "\n",
    "def test_model(data_loader, model, loss_function, device):\n",
    "    # Test a deep learning model on a given dataset and compute the test loss.\n",
    "\n",
    "    num_batches = len(data_loader)\n",
    "    total_loss = 0\n",
    "\n",
    "    # Set the model in evaluation mode (no gradient computation).\n",
    "    model.eval()\n",
    "\n",
    "    # Initialize an array to store loss values.\n",
    "    ddp_loss = torch.zeros(3).to(device)\n",
    "    for batch_idx, (X, y) in enumerate(data_loader):\n",
    "        X = X.to(torch.float32)\n",
    "        y = y.to(torch.float32)\n",
    "        # Move data and labels to the appropriate device (GPU/CPU).\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        # Forward pass to obtain model predictions.\n",
    "        output = model(X)\n",
    "\n",
    "        # Compute loss and add it to the total loss.\n",
    "        total_loss += loss_function(output, y).item()\n",
    "\n",
    "        # Update aggregated loss values.\n",
    "        ddp_loss[0] += F.mse_loss(output, y, reduction=\"sum\").item()\n",
    "        ddp_loss[2] += len(X)\n",
    "\n",
    "    # Calculate the average test loss.\n",
    "    avg_loss = total_loss / num_batches\n",
    "\n",
    "    # Synchronize and aggregate loss values in distributed testing.\n",
    "    dist.all_reduce(ddp_loss, op=dist.ReduceOp.SUM)\n",
    "\n",
    "    # Print the test loss on the master process (rank 0).\n",
    "    if rank == 0:\n",
    "        test_loss = ddp_loss[0] / ddp_loss[2]\n",
    "        print(\n",
    "            \"Test set: Average loss: {:.4f}\\n\".format(test_loss)\n",
    "        )\n",
    "\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t2m</th>\n",
       "      <th>sh2</th>\n",
       "      <th>d2m</th>\n",
       "      <th>r2</th>\n",
       "      <th>u10</th>\n",
       "      <th>v10</th>\n",
       "      <th>tp</th>\n",
       "      <th>mslma</th>\n",
       "      <th>orog</th>\n",
       "      <th>tcc</th>\n",
       "      <th>...</th>\n",
       "      <th>td</th>\n",
       "      <th>relh</th>\n",
       "      <th>srad</th>\n",
       "      <th>pres</th>\n",
       "      <th>mslp</th>\n",
       "      <th>wspd_sonic</th>\n",
       "      <th>wmax_sonic</th>\n",
       "      <th>wdir_sonic</th>\n",
       "      <th>precip_total</th>\n",
       "      <th>snow_depth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.686689</td>\n",
       "      <td>-1.456658</td>\n",
       "      <td>-2.593694</td>\n",
       "      <td>0.425578</td>\n",
       "      <td>0.628146</td>\n",
       "      <td>-0.997964</td>\n",
       "      <td>-0.149173</td>\n",
       "      <td>1.969375</td>\n",
       "      <td>0.859146</td>\n",
       "      <td>-0.982468</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.461559</td>\n",
       "      <td>0.118781</td>\n",
       "      <td>-0.645879</td>\n",
       "      <td>1.056747</td>\n",
       "      <td>1.856894</td>\n",
       "      <td>-0.801430</td>\n",
       "      <td>-0.892522</td>\n",
       "      <td>1.057858</td>\n",
       "      <td>-0.136412</td>\n",
       "      <td>1.077897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.679287</td>\n",
       "      <td>-1.456658</td>\n",
       "      <td>-2.586378</td>\n",
       "      <td>0.407887</td>\n",
       "      <td>0.619968</td>\n",
       "      <td>-0.860817</td>\n",
       "      <td>-0.150046</td>\n",
       "      <td>1.948015</td>\n",
       "      <td>0.859146</td>\n",
       "      <td>-0.982468</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.451835</td>\n",
       "      <td>0.047295</td>\n",
       "      <td>-0.645879</td>\n",
       "      <td>1.067192</td>\n",
       "      <td>1.855431</td>\n",
       "      <td>-0.478831</td>\n",
       "      <td>-0.496964</td>\n",
       "      <td>1.111881</td>\n",
       "      <td>-0.136412</td>\n",
       "      <td>1.077903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.708742</td>\n",
       "      <td>-1.463925</td>\n",
       "      <td>-2.650303</td>\n",
       "      <td>0.248675</td>\n",
       "      <td>0.507512</td>\n",
       "      <td>-0.574234</td>\n",
       "      <td>-0.150046</td>\n",
       "      <td>1.959407</td>\n",
       "      <td>0.859146</td>\n",
       "      <td>-0.982468</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.447777</td>\n",
       "      <td>0.103507</td>\n",
       "      <td>-0.645879</td>\n",
       "      <td>1.082666</td>\n",
       "      <td>1.873927</td>\n",
       "      <td>-0.501771</td>\n",
       "      <td>-0.570396</td>\n",
       "      <td>0.892974</td>\n",
       "      <td>-0.136412</td>\n",
       "      <td>1.077902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.738275</td>\n",
       "      <td>-1.468770</td>\n",
       "      <td>-2.674831</td>\n",
       "      <td>0.284055</td>\n",
       "      <td>0.552659</td>\n",
       "      <td>-0.547704</td>\n",
       "      <td>-0.150046</td>\n",
       "      <td>2.022064</td>\n",
       "      <td>0.859146</td>\n",
       "      <td>-0.982468</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.462928</td>\n",
       "      <td>0.068202</td>\n",
       "      <td>-0.645879</td>\n",
       "      <td>1.041356</td>\n",
       "      <td>1.838030</td>\n",
       "      <td>-0.606911</td>\n",
       "      <td>-0.551641</td>\n",
       "      <td>0.951283</td>\n",
       "      <td>-0.136412</td>\n",
       "      <td>1.077898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.747458</td>\n",
       "      <td>-1.471192</td>\n",
       "      <td>-2.691741</td>\n",
       "      <td>0.266365</td>\n",
       "      <td>0.608748</td>\n",
       "      <td>-0.324456</td>\n",
       "      <td>-0.149173</td>\n",
       "      <td>1.995008</td>\n",
       "      <td>0.859146</td>\n",
       "      <td>-0.982468</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.514199</td>\n",
       "      <td>0.270833</td>\n",
       "      <td>-0.645879</td>\n",
       "      <td>1.089104</td>\n",
       "      <td>1.922688</td>\n",
       "      <td>-1.006449</td>\n",
       "      <td>-0.977891</td>\n",
       "      <td>0.941492</td>\n",
       "      <td>-0.136412</td>\n",
       "      <td>1.077902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27161</th>\n",
       "      <td>-2.347836</td>\n",
       "      <td>-1.442123</td>\n",
       "      <td>-2.511080</td>\n",
       "      <td>-0.600458</td>\n",
       "      <td>1.056732</td>\n",
       "      <td>-1.147341</td>\n",
       "      <td>-0.150046</td>\n",
       "      <td>-0.366031</td>\n",
       "      <td>-1.163945</td>\n",
       "      <td>-0.982468</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.435793</td>\n",
       "      <td>-0.285031</td>\n",
       "      <td>-0.645873</td>\n",
       "      <td>-0.842828</td>\n",
       "      <td>0.048100</td>\n",
       "      <td>-0.239688</td>\n",
       "      <td>-0.157813</td>\n",
       "      <td>1.289472</td>\n",
       "      <td>-0.136412</td>\n",
       "      <td>1.078189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27162</th>\n",
       "      <td>-2.365678</td>\n",
       "      <td>-1.434856</td>\n",
       "      <td>-2.468205</td>\n",
       "      <td>-0.423555</td>\n",
       "      <td>1.074995</td>\n",
       "      <td>-0.992587</td>\n",
       "      <td>-0.150046</td>\n",
       "      <td>-0.387391</td>\n",
       "      <td>-1.163945</td>\n",
       "      <td>-0.982468</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.388672</td>\n",
       "      <td>-0.122907</td>\n",
       "      <td>-0.645875</td>\n",
       "      <td>-0.829546</td>\n",
       "      <td>0.059868</td>\n",
       "      <td>-0.059974</td>\n",
       "      <td>0.001064</td>\n",
       "      <td>1.246095</td>\n",
       "      <td>-0.136412</td>\n",
       "      <td>1.078189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27163</th>\n",
       "      <td>-2.382223</td>\n",
       "      <td>-1.422743</td>\n",
       "      <td>-2.394706</td>\n",
       "      <td>-0.116924</td>\n",
       "      <td>1.237549</td>\n",
       "      <td>-0.813541</td>\n",
       "      <td>-0.150046</td>\n",
       "      <td>-0.138186</td>\n",
       "      <td>-1.163945</td>\n",
       "      <td>-0.982468</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.330509</td>\n",
       "      <td>0.063222</td>\n",
       "      <td>-0.645879</td>\n",
       "      <td>-0.834861</td>\n",
       "      <td>0.052070</td>\n",
       "      <td>-0.102376</td>\n",
       "      <td>0.224763</td>\n",
       "      <td>0.829857</td>\n",
       "      <td>-0.136412</td>\n",
       "      <td>1.078193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27164</th>\n",
       "      <td>-2.385624</td>\n",
       "      <td>-1.425166</td>\n",
       "      <td>-2.406956</td>\n",
       "      <td>-0.169995</td>\n",
       "      <td>1.183932</td>\n",
       "      <td>-0.759613</td>\n",
       "      <td>-0.150046</td>\n",
       "      <td>-0.141034</td>\n",
       "      <td>-1.163945</td>\n",
       "      <td>-0.958741</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.376845</td>\n",
       "      <td>-0.016253</td>\n",
       "      <td>-0.645879</td>\n",
       "      <td>-0.864860</td>\n",
       "      <td>0.033925</td>\n",
       "      <td>-0.706734</td>\n",
       "      <td>-0.586875</td>\n",
       "      <td>0.906601</td>\n",
       "      <td>-0.136412</td>\n",
       "      <td>1.078196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27165</th>\n",
       "      <td>-2.369171</td>\n",
       "      <td>-1.420321</td>\n",
       "      <td>-2.388581</td>\n",
       "      <td>-0.158201</td>\n",
       "      <td>1.318810</td>\n",
       "      <td>-0.561484</td>\n",
       "      <td>-0.150046</td>\n",
       "      <td>-0.206540</td>\n",
       "      <td>-1.163945</td>\n",
       "      <td>-0.484193</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.425810</td>\n",
       "      <td>-0.069099</td>\n",
       "      <td>-0.645879</td>\n",
       "      <td>-0.852407</td>\n",
       "      <td>0.058748</td>\n",
       "      <td>-0.104751</td>\n",
       "      <td>0.160017</td>\n",
       "      <td>0.684513</td>\n",
       "      <td>-0.136412</td>\n",
       "      <td>1.078197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27166 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            t2m       sh2       d2m        r2       u10       v10        tp  \\\n",
       "0     -2.686689 -1.456658 -2.593694  0.425578  0.628146 -0.997964 -0.149173   \n",
       "1     -2.679287 -1.456658 -2.586378  0.407887  0.619968 -0.860817 -0.150046   \n",
       "2     -2.708742 -1.463925 -2.650303  0.248675  0.507512 -0.574234 -0.150046   \n",
       "3     -2.738275 -1.468770 -2.674831  0.284055  0.552659 -0.547704 -0.150046   \n",
       "4     -2.747458 -1.471192 -2.691741  0.266365  0.608748 -0.324456 -0.149173   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "27161 -2.347836 -1.442123 -2.511080 -0.600458  1.056732 -1.147341 -0.150046   \n",
       "27162 -2.365678 -1.434856 -2.468205 -0.423555  1.074995 -0.992587 -0.150046   \n",
       "27163 -2.382223 -1.422743 -2.394706 -0.116924  1.237549 -0.813541 -0.150046   \n",
       "27164 -2.385624 -1.425166 -2.406956 -0.169995  1.183932 -0.759613 -0.150046   \n",
       "27165 -2.369171 -1.420321 -2.388581 -0.158201  1.318810 -0.561484 -0.150046   \n",
       "\n",
       "          mslma      orog       tcc  ...        td      relh      srad  \\\n",
       "0      1.969375  0.859146 -0.982468  ... -2.461559  0.118781 -0.645879   \n",
       "1      1.948015  0.859146 -0.982468  ... -2.451835  0.047295 -0.645879   \n",
       "2      1.959407  0.859146 -0.982468  ... -2.447777  0.103507 -0.645879   \n",
       "3      2.022064  0.859146 -0.982468  ... -2.462928  0.068202 -0.645879   \n",
       "4      1.995008  0.859146 -0.982468  ... -2.514199  0.270833 -0.645879   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "27161 -0.366031 -1.163945 -0.982468  ... -2.435793 -0.285031 -0.645873   \n",
       "27162 -0.387391 -1.163945 -0.982468  ... -2.388672 -0.122907 -0.645875   \n",
       "27163 -0.138186 -1.163945 -0.982468  ... -2.330509  0.063222 -0.645879   \n",
       "27164 -0.141034 -1.163945 -0.958741  ... -2.376845 -0.016253 -0.645879   \n",
       "27165 -0.206540 -1.163945 -0.484193  ... -2.425810 -0.069099 -0.645879   \n",
       "\n",
       "           pres      mslp  wspd_sonic  wmax_sonic  wdir_sonic  precip_total  \\\n",
       "0      1.056747  1.856894   -0.801430   -0.892522    1.057858     -0.136412   \n",
       "1      1.067192  1.855431   -0.478831   -0.496964    1.111881     -0.136412   \n",
       "2      1.082666  1.873927   -0.501771   -0.570396    0.892974     -0.136412   \n",
       "3      1.041356  1.838030   -0.606911   -0.551641    0.951283     -0.136412   \n",
       "4      1.089104  1.922688   -1.006449   -0.977891    0.941492     -0.136412   \n",
       "...         ...       ...         ...         ...         ...           ...   \n",
       "27161 -0.842828  0.048100   -0.239688   -0.157813    1.289472     -0.136412   \n",
       "27162 -0.829546  0.059868   -0.059974    0.001064    1.246095     -0.136412   \n",
       "27163 -0.834861  0.052070   -0.102376    0.224763    0.829857     -0.136412   \n",
       "27164 -0.864860  0.033925   -0.706734   -0.586875    0.906601     -0.136412   \n",
       "27165 -0.852407  0.058748   -0.104751    0.160017    0.684513     -0.136412   \n",
       "\n",
       "       snow_depth  \n",
       "0        1.077897  \n",
       "1        1.077903  \n",
       "2        1.077902  \n",
       "3        1.077898  \n",
       "4        1.077902  \n",
       "...           ...  \n",
       "27161    1.078189  \n",
       "27162    1.078189  \n",
       "27163    1.078193  \n",
       "27164    1.078196  \n",
       "27165    1.078197  \n",
       "\n",
       "[27166 rows x 34 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_ls[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "X shape torch.Size([10, 9, 16, 33])\n",
      "y shape torch.Size([10, 9, 8])\n",
      "my shape torch.Size([10, 9, 16, 33])\n",
      "# of vars 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aevans/miniconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([10, 9, 8])) that is different to the input size (torch.Size([10, 72, 8])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (72) must match the size of tensor b (9) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ix_epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, EPOCHS \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch\u001b[39m\u001b[38;5;124m\"\u001b[39m, ix_epoch)\n\u001b[0;32m----> 3\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m train_model(\n\u001b[1;32m      4\u001b[0m         train_loader, model, loss_func, optimizer, device, ix_epoch\n\u001b[1;32m      5\u001b[0m     )\n\u001b[1;32m      6\u001b[0m     test_loss \u001b[38;5;241m=\u001b[39m test_model(test_loader, model, loss_func, device)\n\u001b[1;32m      7\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "Cell \u001b[0;32mIn[39], line 17\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(data_loader, model, loss_function, optimizer, device, epoch)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Forward pass and loss computation.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m output \u001b[38;5;241m=\u001b[39m model(X)\n\u001b[0;32m---> 17\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Zero the gradients, backward pass, and optimization step.\u001b[39;00m\n\u001b[1;32m     20\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:536\u001b[0m, in \u001b[0;36mMSELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 536\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mmse_loss(\u001b[39minput\u001b[39;49m, target, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/nn/functional.py:3294\u001b[0m, in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3291\u001b[0m \u001b[39mif\u001b[39;00m size_average \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   3292\u001b[0m     reduction \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3294\u001b[0m expanded_input, expanded_target \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mbroadcast_tensors(\u001b[39minput\u001b[39;49m, target)\n\u001b[1;32m   3295\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_nn\u001b[39m.\u001b[39mmse_loss(expanded_input, expanded_target, _Reduction\u001b[39m.\u001b[39mget_enum(reduction))\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/functional.py:74\u001b[0m, in \u001b[0;36mbroadcast_tensors\u001b[0;34m(*tensors)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function(tensors):\n\u001b[1;32m     73\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(broadcast_tensors, tensors, \u001b[39m*\u001b[39mtensors)\n\u001b[0;32m---> 74\u001b[0m \u001b[39mreturn\u001b[39;00m _VF\u001b[39m.\u001b[39;49mbroadcast_tensors(tensors)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (72) must match the size of tensor b (9) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "for ix_epoch in range(1, EPOCHS + 1):\n",
    "    print(\"Epoch\", ix_epoch)\n",
    "    train_loss = train_model(\n",
    "        train_loader, model, loss_func, optimizer, device, ix_epoch\n",
    "    )\n",
    "    test_loss = test_model(test_loader, model, loss_func, device)\n",
    "    scheduler.step()\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16 ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "44818f36aeaf89db1a1d21a2bee6031a28b4e41595a65903b38b9b0c4417365f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
